{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Sparse Data and Embeddings - Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/advanced-solutions-lab/mlcc/sparse_data_embedding/test.tfrecord -O /tmp/test.tfrecord\n",
    "!wget https://storage.googleapis.com/advanced-solutions-lab/mlcc/sparse_data_embedding/train.tfrecord -O /tmp/train.tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to Task 3: Use an embedding with a DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** *In practice, we might project to dimensions higher than 2, like 50 or 100.  But for now, 2 dimensions is easy to visualize.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython import display\n",
    "from sklearn import metrics\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# First, set up a dictionary that allows us to parse out the features from the\n",
    "# tf.Examples\n",
    "features_to_types_dict = {\n",
    "    \"terms\": tf.VarLenFeature(dtype=tf.string),\n",
    "    \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32)}\n",
    "\n",
    "# Create an input_fn that parses the tf.Examples from the given file pattern,\n",
    "# and split these into features and targets.\n",
    "def _input_fn(input_file_pattern):\n",
    "  features = tf.contrib.learn.io.read_batch_features(\n",
    "    file_pattern=input_file_pattern,\n",
    "    batch_size=25,\n",
    "    features=features_to_types_dict,\n",
    "    reader=tf.TFRecordReader)\n",
    "  targets = features.pop(\"labels\")\n",
    "  return features, targets\n",
    "\n",
    "\n",
    "informative_terms = [ \"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n",
    "                      \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n",
    "                      \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n",
    "                      \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n",
    "                      \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n",
    "                      \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n",
    "                      \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n",
    "                      \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n",
    "                       \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n",
    "                       \"drama\", \"family\", \"man\", \"woman\", \"boy\", \"girl\" ]\n",
    "\n",
    "# Create a feature column from \"terms\", using feature hashing.\n",
    "terms_feature_column = tf.contrib.layers.sparse_column_with_keys(column_name=\"terms\",\n",
    "                                                                 keys=informative_terms)\n",
    "\n",
    "########################## SOLUTION CODE ########################################\n",
    "terms_embedding_column = tf.contrib.layers.embedding_column(terms_feature_column, dimension=2)\n",
    "feature_columns = [ terms_embedding_column ]\n",
    "\n",
    "classifier = tf.contrib.learn.DNNClassifier(\n",
    "  feature_columns=feature_columns,\n",
    "  hidden_units=[10,10],\n",
    "  optimizer=tf.train.AdagradOptimizer(\n",
    "    learning_rate=0.1),\n",
    "  gradient_clip_norm=5.0\n",
    ")\n",
    "#################################################################################\n",
    "\n",
    "classifier.fit(\n",
    "  input_fn=lambda: _input_fn(\"/tmp/train.tfrecord\"),\n",
    "  steps=1000)\n",
    "\n",
    "evaluation_metrics = classifier.evaluate(\n",
    "  input_fn=lambda: _input_fn(\"/tmp/train.tfrecord\"),\n",
    "  steps=1000)\n",
    "print \"Training set metrics:\"\n",
    "for m in evaluation_metrics:\n",
    "  print m, evaluation_metrics[m]\n",
    "print \"---\"\n",
    "\n",
    "evaluation_metrics = classifier.evaluate(\n",
    "  input_fn=lambda: _input_fn(\"/tmp/test.tfrecord\"),\n",
    "  steps=1000)\n",
    "\n",
    "print \"Test set metrics:\"\n",
    "for m in evaluation_metrics:\n",
    "  print m, evaluation_metrics[m]\n",
    "print \"---\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
